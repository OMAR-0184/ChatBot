ğŸ¤– AI Chatbot Agents
ğŸš€ An interactive AI chatbot powered by Groq & OpenAI models, with optional web search integration, and a sleek Streamlit UI!

âœ¨ Features
âœ… Multiple AI Models â€“ Supports Llama 3, Mixtral, and GPT-4o


âœ… FastAPI Backend â€“ High-performance API handling


âœ… Streamlit UI â€“ Simple and interactive frontend


âœ… Web Search Integration â€“ Uses Tavily API for real-time search


âœ… Dynamic Model Selection â€“ Choose between Groq & OpenAI


âœ… Easily Deployable â€“ Can be hosted on Streamlit Cloud, Render, Railway, Fly.io



ğŸ›  Technologies Used


ğŸ”¹ Python â€“ Core programming language


ğŸ”¹ FastAPI â€“ Lightweight backend framework


ğŸ”¹ Streamlit â€“ UI framework for interactive apps


ğŸ”¹ LangGraph â€“ AI agent framework


ğŸ”¹ Groq API â€“ For Llama 3 & Mixtral models


ğŸ”¹ OpenAI API â€“ For GPT models


ğŸ”¹ Tavily API â€“ Enables web search


ğŸ”¹ Uvicorn â€“ ASGI server for FastAPI


ğŸ’» How to Run Locally


1ï¸âƒ£ Clone the Repository

```
git clone https://github.com/your-repo-name.git
cd your-repo-name
```

2ï¸âƒ£ Create a Virtual Environment
```
python -m venv venv
source venv/bin/activate  # On macOS/Linux
venv\Scripts\activate      # On Windows
```
3ï¸âƒ£ Install Dependencies

```pip install -r requirements.txt```


4ï¸âƒ£ Set Up Environment Variables


Create a .env file and add your API keys:

```
GROQ_API_KEY=your_groq_api_key
OPENAI_API_KEY=your_openai_api_key
TAVILY_API_KEY=your_tavily_api_key
```
5ï¸âƒ£ Start the Backend Server

```uvicorn backend:app --host 127.0.0.1 --port 8000 --reload```


6ï¸âƒ£ Run the Streamlit UI

```streamlit run frontend.py```

Now, open your browser and go to http://localhost:8501 to chat with the AI agent! ğŸ‰

ğŸ“¢ Future Enhancements
ğŸš€ Support for more AI models
ğŸš€ Deploy on cloud platforms
ğŸš€ Multi-agent interactions

